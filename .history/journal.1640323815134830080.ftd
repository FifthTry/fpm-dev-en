


-- ft.page:


-- ft.h0: FPM Journal


-- ft.h1: Thoughts: Browsing History


-- ft.h1: Readership Tracking


-- ft.h1: Linking Using Package Dependency

So links never break (and original author can keep updating document URL at whim).


-- ft.h1: Git Tracking


-- ft.h1: Font Support Added

24th Dec 2021

After [fixing font issue in 
FTD](https://github.com/FifthTry/ftd/commit/0ce8a3cc3a115a0dca06b9d06824641bc4bc42a4), 
finally we got FPM working with custom Google Fonts (any font for that matter 
should work).

We had an easy way to fix and a "correct" way to fix it. The problem is Font is not
a simple file. Since we have a lot of languages, we can not embed symbols for all
characters in all languages in a single font file, as that would become a large 
file and would slow down websites (and waste CPU/battery/bandwidth). Similarly many
fonts design regular font face, italics, bold etc separately, previously people 
used to just algorithmically slant the characters or make the font bold by 
thickening the lines, but for best effect font designers create custom design for
one or more/all characters for each font style. So we can not put regular, bold,
italics etc in one file as well, as that too will be wasteful.

So CSS lets you specify multiple font files, for different unicode range and font
face etc, and let browser download the font they need based on the content of the
current page.

TODO


-- ft.h1: Doc/TOC Subtree Re-levelling Problem

23rd Dec 2021

So I said including content from other package is proving to be challenging. Lets
see the problem. We have to modes of including contents from other packages.


-- ft.h2: Doc Sub-Tree Includes

In this say we have a document, and in that document I want to include some content
from another document. If I want to include just an image, or a table or a code
snippet from that document then life is easy. But what if I want to include an 
entire heading subtree?

Say that document has been organised into using heading `h1`, `h2`, `h3` etc, and 
say I want to include the entire heading subtree rooted at second `h2` or third 
`h1`. To not have to complicate life we can given that specific `h2` an `id`. 

So we want to include that entire `h2` in current document, including that `h2`'s
descendents like `h3` etc, all code and images and tables of that `h2`. We can 
write something like this:


-- ft.code:
lang: ftd

\-- include: the-id-of/the-document
id: the-id-of-the-h2


-- ft.markdown:

Now lets assume that the document where we are including that `h2` does not have
that much complexity, and it wants to include that `h2` at `h1` level.

This is the "re-levelling" problem. We may want to write something like this:


-- ft.code:
lang: ftd

\-- include: the-id-of/the-document
id: the-id-of-the-h2
level: h1


-- ft.h3: Cross Package Component Visual Harmonisation

First challenge is if the content is from a different package, the two packages
may have different ideas on how to show a code snippet or a table etc. 

Package Interface, and package aliasing are features that we are working towards to
solve this problem. So if you include the package as a dependency and overwrite it
transitive dependencies to use a package you provide instead of the package the
original package author requested (as long as the substituted package confirms to
the package interface of the package being substituted), we achieve component
visual harmonisation.


-- ft.h3: Re-Levelling Challenge

In visual harmonisation we had to map `foo.code` to `bar.code`, the name of 
component was the same, the package where the component was imported was 
substituted, this is easy to implement in `ftd::Library::get()` method.

But here was have to replace each instance of `foo.h2` with an `foo.h1`, and 
`foo.h3` with `foo.h2` and so on. Problem is how `foo.code` is not going to change.
So how do we find what are the promotion/demotion rules for any component in any
package.

We can try to solve it by creating promotion rule entry in `FPM.ftd`:


-- ft.code:
lang: ftd

\-- package: foo

\-- promotion-rules:
heading-2: heading-1
heading-3: heading-2
heading-4: heading-3


-- ft.markdown:

With these rules in place we are saying 1. only the components listed in 
`promotion-rules` are to be promoted or demoted, and 2. `heading-2` can be 
promoted to `heading-1` and demoted to `heading-3` and so on.


-- ft.h2: TOC Sub-Tree Includes

This is the scenario that a package a table of content, and it wants to include
multiple documents from another package in the table of content. The challenge in
this case is "re-levelling" document "roles" like "Chapter" or "Section" and so on.
In original package the subtree we want to include may be just a section, but in
current package we may want to import it a chapter level.

If the documents know about their role, eg the title of a document was "section 
1: introduction", it will read wrong if it's included as a chapter. Also chapter
numbering must not be part of the document.

One thought for this is to define variables like `fpm.role` and `fpm.role-numner`,
and asking documents to use these variables instead of making assumptions about
their roles etc.


-- ft.h1: Challenges In "Remixing" Text Content

22nd Dec 2021

Since Monday, I and Shobhit has been spending lot of time discussing how best to
allow people to include content from package into another.

Things are easier with data. Say you have a package that has defined some list or
variable or some record, you can easily import that package, and iterate through
that list or use the variable, and create your custom visualisations etc. This 
part of FTD/FPM is working well already.

But when it comes to text content, it proving to be surprisingly hard.


-- ft.h1: Remixing Books: Documents from Dependency Packages

21st Dec 2021

When we are writing software we do not start from scratch, we take existing 
libraries and build on top of them. When writing on the other hand, say a book, we
somehow live in the world where the assumption is every last word must be written
or well its not a book.

It is not like we do not have open licensing available today for prose and creative
writing. Creative Commons is out there. [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Copyrights) 
is successful project using Creative Commons. Github today has [147,082 Creative 
Commons repositories](https://github.com/search?q=license%3Acc&type=Repositories&ref=advsearch&l=&l=).

Even software documentation like Django documentation, is available in permissible
license, even though it is not Creative Commons. Significant number of open source
software ships with documentation, and usually that documentation is available in 
permissive licenses.

So we have *huge* amount of content available today. And yet we almost never see
the content being "remixed". Work being built on top of existing stuff. Everyone 
writing a new book on say Python feels they must start from scratch.

This I believe is bad for the world. We may think like we have a lot of books but
we do not have enough books written. I once tried to write "Python for PHP 
Developers" and I got quite a good response on Reddit etc. We do not have enough
intermediate level books.

But much worse than books, the real problem is ironically still too many books. 
Like say you are an intern and you want to join FifthTry, you will have to learn
Rust, but then also Diesel, and PostgreSQL. And yes Django. And possibly even Elm.
Some JavaScript. Some CSS. And of course enough about Linux, and AWS? And this is 
assuming they do not have to learn any FifthTry specific stuff. Which they still 
have to. What is FTD? How we deploy our services, how we do things and so forth.

Imagine there was a great book written about each of these topics, am I supposed to
hand that many books to an intern who joins us? Maybe not all of them but it still
many books.

How about if there was just one book? Think about it. Do we really need to learn
whole of Django? Of course not, we only use Django for database modelling and 
migrations, so they must not actually read about django views and admin and 
template and so on. If you think about it telling an intern to learn any of them
is itself really hard. How much of Rust should they know? How do you even talk
about it? Every team that uses Rust uses a different aspect of Rust. 

Should you learn about things that's not directly pertinent to your job, the exact
task? Of course learning is never bad, but we have only so much time, and if you
not smart about it you may end up spending too much of your precious learning time
learning things that may not be used for the job at the expense of other stuff that
you will need. Knowledge acquisition simply can not be done in depth first fashion,
since it's a bottom less pit.

In summary we want people to be able to create books or dedicated websites for 
learning something, or compilation of information, knowledge, data etc, by using
other packages as dependencies. This can allow "knowledge curators" to create
learning paths for specific audiences.


-- ft.h1: Translation UI Design & Multi FTD Technique

20th Dec 2021

Me and Arpita worked further on the design of translation UI. Check out [this 
commit](https://github.com/FifthTry/fpm/commit/20e709dfb5f30cae9db33d3ca2b97357c4fc3872)
to see the basic skeleton of our design.

The key idea is now we will have multiple base HTML files, `with-fallback.html`
and `with-message.html`, which will be created with content of more than one FTD
documents. For example `with-message.html` will render a "message document" and
a "main document". Further, individual documents can be shown and hidden using 
basic DOM style manipulation (`display: none` etc).

We are going to need a new feature in FTD, ["message-host"](/ftd/~/127/), which
will allow an event handler to message the "ftd host" (also in future we are going
to rename FTD "Library" terminology to "FTD Host"). 

Our `with-fallback.html` will come with a `show_main()` and `show_fallback()` host
messages that our "message ftd" file will be able to trigger using `$event-click$:
message-host show-main` etc.

We are quite happy with this design for now. I wrote couple of feature requests
that can be implemented using this: ["banner support"](/fpm/~/32/) and [encryption
support](/fpm/~/33/).


-- ft.h1: Can Translation Package Use Tracking?

19th Dec 2021

A relatively strong consideration for designing translation, especially translation
of versioned packages is that "translation can not alter logical content" rule.
Consider `1.0/intro.txt` vs `1.1/intro.txt`. Consider a question: who decides if
`1.1/intro.txt` must exist? Original package only, or can translation package also
decide this? Is it possible that in original we only have `1.0/intro.txt` and no
`1.1/intro.txt`, which means as per the maintainers of original package, who 
supposedly are working closest with the actual software being translated, as per
them there is no need for `1.1/intro.txt`, that there is no software change between
`1.0` and `1.1` such that `intro.txt` content changes. But can translation 
maintainers take overwrite this call and still decide to have `1.1/intro.txt`?

What if the original `1.0/intro.txt` had only so much content and translation team
not only translated but decided to expand the intro and cover more topics in the
intro? If they do then original and translated intro have logically diverged. It 
would then not be accurate to say that this is just a translation, it is not an 
independent work which was derived from the original.

I am not saying logical changes, derivative work shouldn't be allowed, just that 
one should be aware when they are doing it. Some authors may be okay with their
work being translated "faithfully" in other languages, but may not like their work
editorialised or "improved upon" by others (and sold / marketed in the original
author's name). I as an author may not be able to read how you have altered my work
in Chinese or some, so how can I as an author endorse it? I don't even know what's
in it, maybe the change is minor but its really hard to say what is minor and what
is not. A little thing the translator decided to omit as its too early to mention
this feature, maybe the reason people would not buy that product because the author
knew that that feature must be mentioned earlier as author knows the audience 
better than the translator. 

Bottom line is there should be a clean line between translation and derivative 
work. And authors should be allowed to say they are okay with strict translation
and may not have energy to whet the "editorialisations" and may not want 
derivative work. 

So when we are talking about translation so far, we are talking about the stricter
translation, no logical changes, as faithful as vagaries of natural languages 
allows one to be.

Let's talk about tracking now. Tracking basically says "hey this document has 
changed, and you said that document depends on this document, so maybe consider 
updating that document". 

Now one can argue that tracking should not be allowed in translation packages. If 
you want to be strict, you maybe tempted to say the only document a translated 
document should be allowed to track is the corresponding document in original 
package. 

By and large I agree with assessment. There is one exception tho: what if say you
are also maintaining a "translated glossary". This document may not exist in 
original, but in every translation one must maintain a document that lists what's
the translated term we are using for each interesting technical term in the 
original language. If we start from scratch, two different translators can pick
two different ways to translate a term, and that may not be good for readers. So
this document should be present, and one can argue every document in the translated
package should be tracking the glossary file.

We are planning to implement a [feature in 
`ftd`](///www.fifthtry.com/fifthtry/ftd/~/9/), which can make this consideration
redundant though, do not put translated term in respective documents at all, but
refer to them from a common glossary file via ftd markup references so if 
translation for a term changes all documents using that automatically get the 
latest version.

Where does it leave us? Disallow tracking in translation packages?


-- ft.h1: Translation Way Forward

17th Dec 2021

So Arpita has heroically built the entire translation feature almost. 
`fpm translation-status` is working. It looks for status of all documents in 
original package by reviewing content of `.track` and shows status for each file
like "Never Marked", "Update Date" etc.

TODO: Arpita to give me sample output of the command.

She has also implement fallback based build: if `django-hi/intro.ftd` doesn't exist
we look for `django/intro.ftd`.

Next: We will build `fpm mark-upto-date` to keep updating translation status.

We also discussed if django has N dependencies do we auto include them in 
`django-hi` if `django-hi` is a translation? Or should each translation mention 
each dependency explicitly? For translation we may want to use the translation of 
a dependency instead of the original package, and while doing so we would need to 
be able to rename and keep using the same name.

Next we also have to add `language` in `fpm::Package`, and ensure that key is set
if current package is `translation-of` some "original package". Original package
must also have the `language` set and the languages must be different. Also 
`translation-of` can't be "chained", if this package is a translation of some other
package then no other package can translate this package, everyone must translate
the same package, each translation "cluster" has a single original translation
package that every package in that cluster is translating.

Finally we need to come to UI. We have a few scenarios, say translation doesn't 
exist for some document, in which case we have to show a message on top saying you
are seeing the English version because this document is not yet translated in 
Hindi. Similarly we need UI for "never marked", "out-of-date" and "upto date".

We want people to be able to control these messages, these messages themselves must
be translated. We will have files `FPM/{missing, never-marked, out-of-date}.ftd`, 
if they are not present we will have some fallback message. When creating a new
translation using a future `fpm create-translation` command we will auto create
these files maybe.

In never-marked and out-of-date scenarios we will have three FTD files to build, 
which will go in the generated `.html` file. The "message" file will show on the
top of the page, and then one of the two, original and translation, would be shown
and the "message" file will have a button with an `$event-click$: call-js 
<function-name>`, and we will have FPM.js file, which will have functions 
`show-original` and `show-translation` (and a "client variable: 
`fpm.showing-original`).

We will also need other server variables to be used when building "message" file 
with variables like `original-language`, `translation-language`, 
`translation-status: "never marked" etc`, `original-marked-on-date`, 
`original-latest-date`, `original-diff` etc.


-- ft.h1: Document-Name and Package Ambiguities

15th Dec 2021


When referring to a document, we use a document id. The document id for a document
in current package is the relative path from package root. If we are referring to
a document from another package, we use `<package-name>:<document-name>`, the colon
separated path. 

On its own if you see `x`, it can either be a document in current package, you may
ask why no `x.ftd`? Are we allowing `x/index.ftd` to be referred to by `x`? No. Our
`index.ftd` is only special at package root level, and not at individual folder 
level, we follow `x.ftd` and `x/y.ftd` convention and do not fall back to 
`x/index.ftd`, `x/y.ftd` as say node etc do. There are advantages to fall back, eg
whole of `/x/*` is in a folder `x`, this leads to some simplicity, eg if you want
to ignore that path, you have to no ignore `x/` folder as well as `x.ftd` file.

We also have complications around import path in ftd documents vs file paths on
command line. If you want to import `x.ftd` you write `-- import: x`, without the
extension. Does that mean when you want to refer to `x.ftd` anywhere in FPM context
it must be `x`? Like on command line if you want to add tracking on `x.ftd` or sync
`x.ftd` do you use `x` or `x.ftd`? 

We can have a rule, if only ftd file is meaningful in any context, eg in import
statement, you can not import a `.txt` file, but you can track `.txt` file, so if
only `.ftd` is allowed for something we use the path without `.ftd` extension and
any file can be passed we use the extension.

We can also standardise on file vs document terminology. Document in FPM context
strictly means it is a FTD file, where as file means any file. So function names,
parameters etc can use `print_file()` or `print_document()` etc naming convention.

There is one more complexity. Say you have a `logo.png` file, there can also be a 
`logo.png.ftd` file which contains the meta data or web index of the `logo.png`. We
can argue that this is too much complexity and lets have no such special 
convention. For example this causes another complexity as to what should be the URL
of such `logo.png.ftd` file? The URL of `logo.png` is `/logo.png` if it is at 
package root, but for `x.ftd` the URL is `/x/` so with this logic the URL of 
`logo.png.ftd` would be `/logo.png/`, and having different content based on 
presence or absence of a trailing `/` in URL seems to be a bad idea. Or maybe we do
it based on "accept" header, if you request an HTML for `/logo.png` you get the
content of `logo.png.ftd` and if you request image you get the `.png`. But then how
would you link to the file? Say you want to open an image in a new tab?


-- ft.h1: TranslationStatus Output

14th Dec 2021

`fpm` cli currently is littered with `println()` and `eprintln()` calls all over
the place. This works okay if we assume that output will always be on terminal, but
we want to support JSON output as well. Also even if we did not want to, in 
general this is bad software design as if the code on how to show output is spread
over the entire crate then its harder to modify it, test it etc.

What we should do instead if each of the commands that we have must have a 
corresponding output type define. Currently we return just a success indicator, and
the return is returned as some custom error type, which in general sounds good but
has no provision for warnings etc, say if you are building `cp` someone asked you 
to copy 10 files and you failed to copy the last file, should you only get the 
`Err` part, then you will have to stuff information about the files that were 
successfully parsed inside `Err`, or you say if even one file was successful then
we return `Ok`. 

This is just mis-using `Result`. We can use `Result::Err` to indicate something 
really bad has gone wrong, we could not proceed at all, say the command you tried
to execute does not exist, or the config file is not found. But all other wrong,
eg a given FTD file has bad syntax or could not be read due to permission issues,
we should send all as `Result::Ok`.

Further we should have a type for each command which represents the output, which
can be printed out on stdout with colour highlighting or converted to JSON etc. 
Also, `main()` should do the print to stdout or convert to json etc and not 
individual command handler functions.


-- ft.h1: Arpita Next Steps

13th Dec 2021


- [x] `fpm sync <list of files file>`
- [x] `fpm status <file>` to show all statuses for the file
- [x] `fpm status` to show status of adhoc tracking but not translation stuff
- [x] `fpm stop-tracking`
- [x] `fpm diff <file>` to show all diffs (including tracking diff, translation 
       diff)
- [x] `fpm diff -a` to show everything for every file`
- [x] support tracking, sync, diff for any file, not just ftd files
- [x] allow any file type to track any file type
- [ ] `fpm translation-status`
- [ ] `fpm translation-status <file or folder>`
- [ ] `fpm mark-upto-date a --target b --on <timestamp>`
- [ ] `fpm diff <optional-folder>` to only show regular diff (only changes from 
      `.history` file)


-- ft.h1: `fpm::document` refactor

12th Dec 2021

Been looking at code and found a struct `fpm::document::Document`. Not too happy
with its design right now.

The idea is we have a lot of commands, and many of these commands go through
all the documents in the current package, and `fpm::document::Document` and the
corresponding `get_documents()` gives you a vector of these documents for easier
time handling all files. The main job this `get_documents()` is abstracting over
the directory walking so you do not have to worry about anything and you can just
do a `for d in get_documents()`. Another thing `get_documents()` takes care of is
ignoring documents that should not be handled, eg `.history`, `.track`, `.build`
etc special folders.

I was thinking about what's bothering so much about it. The first thought is 
abstraction and frameworks. I kind of am not fond of them, unless there is a strong
reason. It like a trade, you want to have a nice Mercedes, sure, go ahead, you just
have to pay for it. You cant just wish it. If you want to create a framework you
have to understand all future needs. You have to educate people, it must be well
documented. There must be abstraction boundaries. Everyone must understand what
this framework is doing etc etc. People look at framework and go say I will also 
make one. But I will do all the work later. If you wonder where tech debt comes 
from, this is where it comes from. You went to a Mercedes showroom and drove off
with a shiny car, and told them you will pay for it later. Live with your ballgadi
instead.


-- ft.image:
src: https://i.imgur.com/EKBUF48.jpg

So our bullock-cart should be `std::path::PathBuf`. Also instead of framework - a
full on abstraction over file system, as that is what the `fpm::document` module
is trying to be, an abstraction over file system so you do not have to deal with
file system API - we should think of use cases and write helper methods.

Let's see what all we need? We need to know if the given path is ftd document or
markdown or some static file. Further want to know if some path is top level, 
in-fact there is only one such use case, we only do one special handling, the
top level `index.ftd` maps to `index.html`, every other `.ftd` maps to 
`<without-extension/index.html`. Further during processing we want to report 
relative path of every document being processed, with respect to current directory.

Another thing we need is some sort of expectation if we are running from the 
package root directory or any random path inside it. We want to support the later
case so none of the function should be written with respect to the assumption that
they are running from package root directory. Either that or we assume everything
is running from package root and we do a chdir at the start of the program. If we
do change directory then we still need to keep track of which directory we were 
called from so that during reporting we show the relative paths.

We also need to be able to process the subset of a directory, either the current
directory or a directory whose path was specified on the command line. So whatever
directory walker we need, need that ability. 

Further we want to sometime process files from another package, say in case of 
translation, we want to walk the original package and find corresponding files in
current package. That too we would want to do starting from an arbitrary folder, eg
the folder corresponding to current dir in the original package (eg if package root
is `foo` and you are in currently in `foo/a/b`, and original is `foo-en`, then we
want to traverse all files in `.packages/foo-en/a/b/`).


-- ft.h2: Contract 1: We will change into package root at app start

To simplify things our code can assume they are running from the right place. The 
config object will keep track of the original current directory.


-- ft.h2: Contract 2: We will always use `PathBuf` of `Path` in our program

All paths would be stored in the "Rustonic" way. We will have a method on config
object that converts any path to original current directory relative string for
display purpose.


-- ft.h2: Contract 3: We do not support non UTF-8 paths

In fact we would be using [camino](https://crates.io/crates/camino/1.0.2) for 
storing paths, so we do not have to do `.unwrap()` when converting path to str
everywhere.


-- ft.h2: Contract 4: If `fpm::Config` exists we can be sure its a proper package

We only create `fpm::Config` after verifying the package is proper (it may not
have all the valid ftd files etc, but its FPM.ftd exists and is valid, and its
dependencies have been checked).

We generally want to make as many such guarantee, if there is ever a 
`constructor() -> Result<X>`, since `constructor()` is clearly saying its a 
`Result<>` meaning it could have failed, then rest of the code must be able to 
assume that if it was possible to check validity of `X` it must have been checked
by `constructor()` and they can blindly trust the output of `constructor()`. The
only exception to this is "expensive check scenarios" where its not feasible for
`constructor()` to check everything as that check would be too expensive and 
detrimental to performance of the program. Note that in such cases the 
documentation of `constructor()` must say so, what checks have been left out, and
there must be some `X.deep_check()` or something that will perform the rest of the
expensive checks`.


-- ft.h2: Contract 5: Temporary files are created in `/tmp` etc

We do not litter current directory with partial and temporary folder, like zip file
being downloaded when package is being fetched.


-- ft.h2: Contract 6: We never go beyond the package root

We ensure this by always creating file paths using `config.assert_in_package()`,
which panics if we go beyond the package root. It must not be relied upon to be
the only thing, this is the last resort, all best practices should be used when
creating paths.


-- ft.h1: `fpm fmt`

Added a new [CR about fpm formatter](/fpm/~/31/).


-- ft.h1: Markdown Index Support and 0.1.5 Release

10th Dec 2021

We already supported the conversion of markdown files to HTML during the build 
process. Shobhit has further [added "markdown index" 
support](https://github.com/FifthTry/fpm/pull/16), any directory that says `a` with 
`README.md` in it, without a corresponding `.ftd` file, we render the content of
the `README.md` at `/a/`.

Vipin needed font support, realised we have not released anything for a while
so created a new release.


-- ft.h1: Package Interface and Package Alias

 Was discussing package interfaces, and we have to start creating some of these
package interfaces now, now that package and basic machinery is working fine.

The motivation for package interface, and aliases, is to make it easy to change
themes and "component libraries", without doing much change in your package.

When using a theme or a component library you have to first add them as a 
dependency in your `FPM.ftd`:


-- ft.code:
lang: ftd

\-- import: fpm

\-- fpm.package: foo

\-- fpm.dependency: some-lib


-- ft.markdown:

If we just do this, we can now import `some-lib` from any file in the `foo` 
package. 

But what if we want to change that `some-lib`? First of all, we someone has to 
ensure that the new library is compatible with `some-lib`, else switching would be
a tedious process, we will have to update all calls of `some-lib` with a compatible
component or type in the `new-lib`. What guarantee is there that `new-lib` will 
have corresponding types and components (with same arguments, type and semantics?).

Say `some-lib` has exposed a component `heading` for authoring headings in 
documents:


-- ft.code: using heading from some-lib
lang: ftd

\-- import: some-lib

\-- some-lib.heading: the heading
level: 1


-- ft.markdown:

Now when we switch to `new-lib`, maybe they have decided to expose heading with
the name `h1`, so we have to do the following:


-- ft.code:
lang: ftd

\-- import: new-lib

\-- new-lib.h1: the heading


-- ft.markdown:

Notice the changes: we have updated the import command, then we updated the call
module name part of each reference `some-lib` to `new-lib` and finally we have 
switched from `heading` to `h1` and removed the `level`.


-- ft.h2: Using `import as`

We could have avoided the second by using `import as` feature:


-- ft.code:
lang: ftd

\-- import: some-lib as lib

\-- lib.heading: the heading
level: 1


-- ft.markdown:

In this case, if we have saved the number of edits we have to do when switching
component library, and would have to only focus on the incompatibility between
the two libraries. If the two were compatible we would only have to change one line
in each ftd file when switching a library.


-- ft.h2: Using Package Alias in `FPM.ftd`

We can do better by supporting package alias:


-- ft.code:
lang: ftd

\-- import: fpm

\-- fpm.package: foo

\-- fpm.dependency: some-lib as lib


-- ft.markdown:

Here we have aliased `some-lib` to `lib` in `FPM.ftd` itself, so all the ftd files
in the package can just import `lib` now, and we have to do that much fewer change
when switching:


-- ft.code:
lang: ftd

\-- import: lib

\-- lib.heading: the heading
level: 1


-- ft.markdown:

If the packages were compatible, had same components and types, then we can switch
packages by modifying only one line in the entire package!

But how do we ensure more and more packages are compatible with each other like
this so it's easy for people to switch?


-- ft.h2: Package Interfaces

What if there was a way for a package to say it has exactly the same types and
components exposed as some other package? What if any package can act as an 
"interface", and any other package can "implement" it?

We actually do not want to do anything special to declare that some package is an
interface. Every package is an interface. Just that they are not well known, others
are not going to "implement" that package. But any package can become popular and
others can start targeting that package.

When you are creating a package and implementing an interface, for that matter a
package should be able to implement more than one interface if they happen to be
mutually non-conflicting. Two packages would be "conflicting" if say both exposed
a component "heading", but they take different parameters. Or maybe one uses 
`heading` as a type (say a record name or variable name) and the other has a 
component named `heading`.

Now imagine there was some well-known package, `fifthtry/blog` for example, and
then a package can declare that they implement `fifthtry/blog` by using 
`implements:` package key:


-- ft.code:
lang: ftd

\-- import: fpm

\-- package: some-lib
implements: fifthtry/blog


-- ft.markdown:

And say `new-lib` also has declared that they implement the same. Now our 
`fpm check` (and `fpm build` etc) will check if the contract is indeed valid, if
indeed `some-lib` has exactly the same types and components with compatible names 
and arguments as `fifthtry/blog`, else everything fails.

In fact providing extra components or types, or even extra optional properties to
records or extra optional parameters to components is also fine, our interface 
checker would not mind that.

Now when someone is using `some-lib` they can do the following:


-- ft.code:
lang: ftd

\-- import: fpm

\-- fpm.package: foo

\-- fpm.dependency: some-lib
interface: fifthtry/blog


-- ft.markdown:

Here we have said please use `some-lib`, but do not give let me use any item from
`some-lib`, only the items that are defined in `fifthtry/blog`. We can then import
`fifthtry/blog` from any of our `ftd` files, and our system will know you really
want `some-lib` stuff, so `fifthtry/blog` has become an alias for `some-lib`. With
this, switching to `new-lib` would be guaranteed to work with just one line change.

Finally, we can use both `interface` and `as`, say if the name of the interface 
package is long etc, you can also use alias.


-- ft.code:
lang: ftd

\-- import: fpm

\-- fpm.package: foo

\-- fpm.dependency: some-lib as blog
interface: fifthtry/blog


-- ft.markdown:

Now you can do `-- import: blog` everywhere. There you go, one-line change theme
switching with guarantees. 

We, FifthTry, will seed things with enough packages that act as interfaces, we will
study different domains, resume, photo album/journal, podcast, blog, pricing page,
contact page, testimonials, simple product listing, book review site, books, api,
etc etc, and propose the first set of package interfaces and seed the first set of
professional quality themes for each interface. Once the ball is rolling, the world
will take over.


-- ft.h1: Thoughts: Tangled Documentation

Let's talk about software documentation for a moment. Most programming languages 
have the provision to write documentation as part of code. Consider this code:


-- ft.code:
lang: py

def lower(x):
    "lower() returns the lower cased version of the passed value"""
    x.lower()


-- ft.markdown:

Here the string "lower() returns..." is documentation of `lower()` function, and
it serves two main purposes: 1. it shows up in IDE:


-- ft.image: IDE showing the documentation
src: https://i.imgur.com/rdaUo2D.jpg
width: 500
align: center

And 2. it shows up in pydoc etc generated documentation of the software package. Eg
consider [this page](https://docs.djangoproject.com/en/4.0/ref/models/fields/#django.db.models.CharField).

Java, Rust, many languages have some features like this.


-- ft.h2: Problem 1: Editing Is Hard

If we put documentation in source code, we are basically limiting editing of that
part of the documentation. Not only one has to learn git etc before they can 
contribute, but the lint etc also has to pass. Further, each language has its own 
weirdness you have to learn.


-- ft.h2: Problem 2: Discourages Long Form Documentation

If a project chooses exclusive source-based documentation, it becomes hard to 
include guides, tutorials, overviews etc in the docs. People tend to throw all 
that in an assortment of scattered README and other markdown files.

Projects that use `sphinx` for example do a better job at it, where the 
documentation files drive the extraction of documentation from source files. This
allows people to structure documentation properly.

Internet is full of tutorials and how-tos that should have been part of original
documentation, but because of the high bar on source code.


-- ft.h2: Problem 3: Translation is impossible

If you are putting documentation along with source code you can not include docs
in 10-20 languages now can you? It is simply impossible to have the translation of 
source code documentation based on the current state of tooling.


-- ft.h2: Problem 4: Versioning

It is virtually not possible to update the documentation of any existing published
version of the software. Documentation change is clubbed with software change and
has to through a software release cycle.

I discussed other problems with documentation and versioning on 9th Dec 2021.


-- ft.h2: So What Should Be Done: Tangle And Weave

Like we have [language server 
protocol](https://microsoft.github.io/language-server-protocol/), LSP, supported
today by many editors, we must have some sort of language documentation protocol.
Not protocol maybe, as that implies a network protocol, we should have some 
standard file system, package format or whatever, for where to get documentation
from.

So say we create `fifthtry/pydocs` package interface for documenting python 
packages, or maybe even more specific `fifthtry/python-cli` vs 
`python/django-app` etc. And so on for all programming languages.

We then create tooling to extract source docs from python etc packages and update
the docs. So you have your python source checked out in a folder, and next to it
you have the docs checked out, and there is a tool that extracts all source docs
from python and updates the docs. And then there is another tool that does the
reverse, takes the docs from the docs folder and updates the python files. 

This is sort of literate programming in reverse. You edit docs in source files
and extract docs out of it, and then modify the extracted docs and put them back
in. Javadocs etc do only one step, take out the docs from the source, but they do 
not put things back in.


-- ft.h2: Patching pip/cargo etc

If we set this up, we will then have to patch pip, cargo etc, things that download
source code to fetch the source, then fetch the documentation package in the users
preferred language, and update the source with documentation so IDE can show docs
in the right language.

Of course, you would want to do this only in development builds, in a production 
environment you do not need to do the extra work, nor do you want to mess with line 
numbers in source code so all error stack traces are consistent.

This is basically a hack. Ideally, editors should be updated to support the 
documentation package format itself and show tooltips docs from DPF files instead
of the source file. During development, we do use jump to definition, and often 
scroll to read the docs, so patching source is also needed.


-- ft.h1: Arpita Next Steps

9th Dec 2021


- [x] `fpm sync <list of files file>`
- [x] `fpm status <file>` to show all statuses for the file
- [x] `fpm status` to show status of adhoc tracking but not translation stuff
- [ ] `fpm translation-status`
- [ ] `fpm translation-status <file or folder>`
- [ ] `fpm stop-tracking`
- [ ] `fpm mark-upto-date a --target b --on <timestamp>`
- [ ] `fpm diff <optional-folder>` to only show regular diff (only changes from 
      .history file)
- [ ] `fpm diff <file>` to show all diffs (including tracking diff, translation 
       diff)
- [ ] `fpm diff -a` to show everything for every file`


-- ft.h1: Ad hoc Tracking Is Here!

Arpita has finished implementing the first version of `fpm start-tracking` and 
`fpm mark-upto-date` commands, and updated `fpm status` and `fpm diff` to support 
ad-hoc tracking.


-- ft.h1: Notes on Deleting Files And History

We won't delete the history of a file when a file is deleted. We currently have 
`.history/foo.<timestamp>.ftd` for every modification of `foo.ftd`. We will soon
also have `.history/foo.<timestamp>.ftd.info`.

In some cases only the `.info` file may exist, when `foo.ftd` has been deleted.

`.info` file will also contain the "commit message" of a change. And in future 
when we implement history browsing it will also contain a flag that tells the UI 
to ignore this particular change saying it's a minor thing and is distracting. We 
don't actually delete the timestamp file and merge because timestamps are created 
on sync and after sync it gets published, and others may have stored that timestamp 
in their `.track` file.

Technically, we can manage to miss `.timestamp` files from a `.track` file by 
using the immediate previous entry, but it will cause a double review in edge 
cases. I prefer we never delete the history.


-- ft.h2: `.latest.ftd`

What about `.history/.latest.ftd` file? When a file gets deleted we should not
delete the entry for that file from the `.latest.ftd` file, but instead add a 
`deleted: true` flag to it. If by the same name another file gets created, we will
remove the `deleted: true` flag.


-- ft.h2: Auto Stop Tracking If File Is Deleted?

If `a` is tracking `b` and `b` is deleted, we could remove the tracking 
information from `a.track`. This means if a new file `b` is created in future, 
the user will have again `add-track` it.

Here we are assuming if a file is deleted and another file with the same name is 
created later, the two files are logically not related at all and just happen to
share the name.

We can also show users a warning when they do `fpm status` etc, saying a file is 
gone and prompt them to `stop-tracking` explicitly.


-- ft.h1: Multiple SQLite DB Support

`$processor$: package-query` only supports querying against one sqlite database at
a time. SQLite supports loading more than one sqlite file at a time and we should
be able to support that as well:


-- ft.code:
lang: ftd

\-- string foo:
$processor$: package-query
db foo: foo.sqlite
db bar: path/to/bar.sqlite

SELECT * FROM [foo.table1], [bar.table2]


-- ft.markdown:

We can use the db aliases in the query.


-- ft.h1: Thoughts: SQLite And Build Optimisation

One of the issues with SQLite is we may not be able to do an optimisation.

When things are rendered via `fpm-repo` things are fine, but when using `fpm build`,
things can become a problem if the package size or complexity grows. With support
for HTTP request handling and SQLite queries, and we will be adding a lot of stuff,
we are just getting started, the time it takes `fpm build` may start becoming an
issue.

One way to speed things could be to do build caching, do not rebuild something that
has no change. Consider the simple case, `a.ftd`, which does not import any other 
document. Consider also we do not have dynamic features like `fpm.now` which 
returns the current time. In such cases, we can choose to not rebuild `a.ftd` if 
the content of `a.ftd` hasn't changed. 

We can detect if a document uses another document or dynamic features, and we can
store this information, and use it when to decide if we should rebuild things or 
not. Eg, if we know some document has used `fpm.now` and has no other dependency and
that document's content hasn't changed, we still want to regenerate the 
corresponding html, as `fpm.now` returns a different value on every run.

We can do this optimisation for `sqlite` as well if a random sqlite file has been
used. If the sqlite database file has changed then we need to rebuild the document
that queries that sqlite database even if the document itself hasn't changed.

But when we talk about query against package database, a sqlite database that we
would be creating/updating based on the content of all documents in an fpm package,
that sqlite will always change, and any document that queries that package database
can never be cached.

Unless we break the package database into smaller databases, say for each record
we have a sqlite file, and some document is only interested in instances of that
record, and we know that only a few files have created an instance of that record,
now the out of date graph would be a lot smaller, only those few files. 

Smaller files have problems tho, some queries would want to use join and if the
tables in different database join may not always be possible (not sure how things
would be after the support of referring multiple sqlite databases for a single 
query, can it negate this drawback?). Not sure how foreign key would work etc.

One thing is there that we can do both, generate big databases and individual 
databases as well, and do it opportunistically, only generate the databases that 
were referred by any of the documents. This way we can even choose to not generate
the big package database if no document is querying that database. 

How about a database for use for other packages? Say `package a` wants to query 
database of `package b`? That is slightly simpler because then you are not worrying
about build time but sync or publish time. It may be okay to do more work during
publishing.

But then again why are we calling build all the time? Why are we worried about
performance of the build at all? Because we currently do not support auto reload? 

Auto reload means we have to support the demand generation of pages, in which 
case we don't have to worry about caching, the moment we introduce support for 
`fpm server`, even without auto reload feature, this whole discussion would go
moot. 

Making `fpm build` fast would be important, but then we can ignore it as it's no
longer urgent, as so far my concern was author edit workflow, which would be 
improve much more by auto reload and fpm serve than making `fpm build` fast.


-- ft.h1: Merged: Static File Support Is Here!

Till now `fpm build` used to only process `.ftd` files in an fpm package. Shobhit 
has added support for handling static files (files other than ftd and markdown, and
not ignored by `.gitignore`/`fpm.ignore` etc).

Now we can add images etc as part of an FPM package and they get included in 
generated static site.

Since we kind of now include all files in the current directory, it may be a good 
idea to review the files that are being processed and ignore files you do not want
published, both for performance and security reasons.


-- ft.h1: Thoughts: Security

One kind of thing we have to be constantly aware of when writing/reviewing any FPM
code is accidentally copying say `/etc/passwd` to the built file. This can happen 
say if we started support symlinks, and someone has a package that you are 
contributing to, and symlink gets you to accidentally copy more stuff to `.build`
and publish to the world.

It can happen more than by just symlink, say in `$processor$: package-query`, if
the value of `db` is set to say `../firefox-password-store.sqlite` file, again we
may accidentally read beyond what we should, which is the content of the current 
package or any package that is a direct dependency of this package. In fact, if 
current package depends and a package `a` and `a` depends on `b`, then we must not
allow current package files to directly reference files in `b` without adding an
explicit dependency on `b`, as while this is technically not a security issue, it
causes issues if `a` removes the dependency, the package will suddenly stop 
building.

We are shipping a binary that runs on people's machines, this is a threat vector,
and while its easy to audit code for direct threats (attempt to do mining, or 
scanning stuff), we are also letting our binary download packages from the internet
authored by others, and we have to give guarantees that those files can not do
any harm either. 

Our FTD must not get any feature, for instance, letting people directly execute 
commands from a package, without user understanding the command (this can happen
when a package is being downloaded for the first time, we should show all the 
external commands this fpm package is going to be able to run etc).

The thing is this is very tricky, we can not say we don't want to let package
authors run anything, that will significantly decrease the power of FPM packages.
We have to allow people to query data from their trusted data stores, to make it
part of generated documents, *if they want to*. But we can not surprise people.
Even HTTP requests are sensitive, not just command execution.


-- ft.h1: Markdown Special Variables

- fpm.markdown-filename etc
- fpm.package.name vs FPM.package-specific-variable
- import path disambiguation, can be use : as separator
- `import: <package>:` is ugly, import foo means foo is either in current package
  or a package which is a direct dependency of current package


1. ~`a` (local), `a:` (package index), `a:b/c`~ (`-- import: a:` is ugly)
1. `a` (local or package-index), `a:b/c` (pretty)
1. `@a` (local), `a`, `a:b/c` (explicit)
1. `a` (local), `@a`, `b/c@a`


-- ft.code: generalised import
lang: ftd

\-- import: a as b
from: <package>
exposing: x
exposing: y

\-- import: x as y


-- ft.markdown:

Here, `x` is either a document in current package or a package.


-- ft.code: fpm and markdown
lang: ftd

\-- import: vars
from: fpm

\-- import: fpm


-- ft.markdown:

What if we have `fpm.ftd` in current package, who to import it?


-- ft.code: fpm and markdown
lang: ftd

\-- import: fpm
from: .


-- ft.h1: How do we handle code include?

Currently when using `ftd.code` we include the code block in the body. What if
we wanted to refer to code in a source file?


-- ft.code:
lang: ftd

\-- ft.code:
lang: py
$processor$: include-source
file: a.py
tag: foo


-- ft.code: a.py
lang: py

import os

# FPM-START: foo
def foo():
    print("this is foo")
# FPM-END: foo


-- ft.markdown:

Currently `ftd` `$processor$` can only be used for variables and lists, we have to
extend it to use on component construction as well.

We may also want to specify more than just the body as well, eg other headers.


-- ft.h1: `fpm tracks` and `fpm mark` is here!

Arpita implemented these two commands.

We had a funky `fpm a tracks b` idea, which no command line tool does. She used
the `fpm tracks destination source` syntax. We should make it maybe: 
`fpm start-tracking <f1> --target <f2>`. Also the code assumes we will only track 
`ftd` files, but we have to be able to track any file. Remove `.ftd` prefix
handling.

`fpm mark-upto-date <f1> --target <f2>`. Here target would be optional eventually,
if the target was missing and `f1` tracks more than one file then the cli would 
prompt which file.

If the file is not found it silently returns, should report the error. If file is
already being tracked it should show some message.

Not sure if `fpm diff` should show all the diffs, local modifications and tracking
diff, or should we have a separate command.


-- ft.h1: Explanation Of Dynamic Documents and Actions

8th Dec 2021

TODO: upload the video and link here.


-- ft.h1: 100th Commit! We now honour `.gitignore` etc

Shobhit just [implemented support ignoring files that `git` 
ignores](https://github.com/FifthTry/fpm/commit/c9aded47ef26785a6d49949ddf8b71a09921b5dd). 
You can also ignore more files by populating `fpm.ignore: string list` with 
patterns that are compatible with `.gitignore` file patterns.


-- ft.h1: Some thoughts on Versioning

FPM is for storing documentation and not software. Git is for storing software and
people also use it for storing documentation.


-- ft.h2: Problem With The Way Git / SVN etc Do Versioning

There is a problem with the way Git etc manages versioning that it is not a good 
solution for storing documentation, in my opinion. Traditional "source code 
managers" create a new folder or a branch for managing versioning.

Say you are working on django 1.0 and its time to create django 2.0, you create a
new branch for version 2.0 and start working on it.

At this point, the two branches have diverged. All new changes now go to the 2.0 
branch. You may even make main or master follow the 2.0 branch. For all practical 
reasons, 1.0 has stopped. You will want to be good citizens and support 1.0, 
backport some of the bug fixes, especially security fixes. In projects like Linux 
people even backport whole features to older versions.

But back-porting is kind of extra work. Most people recommend and send a pull 
request against the latest main/master and the changes get included in the next
release that is cut from main/master.


-- ft.h2: Documentation and Software Are Different

Back-porting bug fixes and features are kind of hard. You have to verify software
indeed works correctly. You have to write unit tests and verify there are no 
regressions. Software releases and continuous maintenance is work. It's kind of 
usually best to focus efforts on the latest version and update as soon as one can.

Documentation on the other hand is lot easier. There is no risk of documentation
breaking anything. Wrong documentation can still have consequences, no doubt about
it, but they are rather rare, compared to software issues. Software is a lot more
fragile compared to documentation.

By managing documentation like the software we are doing a dis-service. It's the 
wrong tool for the job.

One difference in documentation compared to software is that a lot of changes in
documentation are not logical. Eg, if the original documentation said this function
takes three arguments and the new one says it takes four, this is a logical 
difference. But if the original documentation was too terse, and new documentation 
gives more examples and explanations and how-tos, the documentation hasn't really 
changed in a logical sense.

It's like refactor in software. We know refactor, should not cause any change in
behaviour of the software. But in software it's really hard to arrive at this 
conclusion, if someone sends a software refactor PR, it's really hard to say that 
will really have no effect, that it's safe to merge. 

But for documentation its almost trivial to see a PR and conclude that there is
no real "logical" change, that it is just a better written tutorial and has not
changed anything fundamental.


-- ft.h2: Updating Documentation For A Published Version Of Software Must Be Possible

Currently, it's almost not possible to update django 1.0 documentation without also
creating a new release of django 1.0. And in that case, it no longer is updating 
the documentation of django 1.0, it's updating documentation of django 1.0.1 or 
whatever.


-- ft.h2: Open Source Maintainers Are Busy Enough

Software is a lot of work. Core maintainers have to review every line like a hawk.
To ensure nothing is broken. That there is no edge case. No violation of any 
contract etc.

So sending documentation only PR to review to them, especially to older versions
of the software, it's almost going a bit too far, demanding too much from them.


-- ft.h2: The Root Problem In Current Documentation Workflow

If we create a new branch for every new version of the software and keep the 
documentation along with software in that branch, we are basically creating a copy
of every file for every version.

Say you have a file `tutorial.txt`, there is one copy of this file in *every* 
version branch. This is the root problem. Even if there is no change in 
`tutorial.txt`, we still copy it over.

We do, what can be called, copy-on-branch, instead of what should be: 
copy-on-incompatible-change.

Let's analyse django:


-- ft.code:
lang: sh

git clone git@github.com:django/django.git
cd django
python t.py
4.0rc1 37 72 27
wc -l tags                                
     312 tags


-- boolean $show-t-py: false


-- ftd.text: Hide `t.py`
if: $show-t-py
$event-click$: toggle $show-t-py


-- ftd.text: Show `t.py`
if: not $show-t-py
$event-click$: toggle $show-t-py


-- ft.code:
if: $show-t-py
lang: py

import sys
import hashlib
import subprocess

def main():
    overview = set()
    tutorial = set()
    install = set()
    for tag in get_tags():
        checkout(tag)
        overview.add(sha256sum("docs/intro/overview.txt")) 
        tutorial.add(sha256sum("docs/intro/tutorial01.txt")) 
        install.add(sha256sum("docs/intro/install.txt")) 
        print(tag, len(overview), len(tutorial), len(install))


def checkout(tag):
    subprocess.run(["git", "checkout", tag]) 

def get_tags():
    return [t.strip() for t in open("tags").readlines()]

def sha256sum(filename):
    h  = hashlib.sha256()
    b  = bytearray(128*1024)
    mv = memoryview(b)
    with open(filename, 'rb', buffering=0) as f:
        for n in iter(lambda : f.readinto(mv), 0):
            h.update(mv[:n])
    return h.hexdigest()

main()


-- ft.markdown:

As you can see, we have 312 tags, and therefore 312 copies of `overview.txt`, 
`tutorial01.txt` and `install.txt` but only 37, 72, and 27 unique content.

If `tutorial01.txt` is modified 72 times, we have to ask how many of those 72 
"logical change", meaning the tutorial was changed because something in django
changed, say some api was added or changed etc, and how many were "English change",
improving the doc. 

If we do the analysis, we can bring down the number of unique copies of 
`tutorial01.txt` to even fewer than 72, maybe only 3 or 4 as django is pretty 
stable and the tutorial for django 2.0 is still applicable for django 4. Lets take
a look at the diff between django 3.0 and 4.0:


-- ft.code:
lang: diff

\--- 3.0.txt	2021-12-08 19:33:26.000000000 +0530
+++ 4.0.txt	2021-12-08 19:31:37.000000000 +0530
@@ -23,7 +23,7 @@
 If Django is installed, you should see the version of your installation. If it
 isn't, you'll get an error telling "No module named django".
 
-This tutorial is written for Django |version|, which supports Python 3.6 and
+This tutorial is written for Django |version|, which supports Python 3.8 and
 later. If the Django version doesn't match, you can refer to the tutorial for
 your version of Django by using the version switcher at the bottom right corner
 of this page, or update Django to the newest version. If you're using an older
@@ -35,10 +35,8 @@


-- ft.markdown:

This is technically a logical change. Though ideally this diff must not have 
existed at all, they should have defined `|minimum-supported-python-version|` like
they have defined `|version|`. As much as possible documentation must used 
variables etc, so they do not go out of date so easily or create such needless 
diffs for humans to review.


-- ft.code:
lang: diff

-    If you're having trouble going through this tutorial, please post a message
-    to |django-users| or drop by `#django on irc.freenode.net
-    <irc://irc.freenode.net/django>`_ to chat with other Django users who might
-    be able to help.
+    If you're having trouble going through this tutorial, please head over to
+    the :doc:`Getting Help</faq/help>` section of the FAQ.


-- ft.markdown:

Seems that they have stopped supporting the IRC. Now this must not have been a 
django 4.0 change, I mean they are not supporting IRC for any version of django,
this must have been a change in django 3.0 docs as well. Imagine how many people
would be using django 3.0 for so long, years and years, and they will all be going
to IRC and they would be failing to get help, wasting time. Why? All because they
decide to create a new branch for versioning and not what they should have done
as I will describe later.


-- ft.code:
lang: diff

     If your background is in plain old PHP (with no use of modern frameworks),
-    you're probably used to putting code under the Web server's document root
+    you're probably used to putting code under the web server's document root
     (in a place such as ``/var/www``). With Django, you don't do that. It's
-    not a good idea to put any of this Python code within your Web server's
+    not a good idea to put any of this Python code within your web server's
     document root, because it risks the possibility that people may be able
-    to view your code over the Web. That's not good for security.
+    to view your code over the web. That's not good for security.


-- ft.markdown:

Again, as you can see, absolutely no reason this is a change django 3.0 users 
should not see, this is completely generic improvement applicable to all django
versions.


-- ft.code:
lang: diff

@@ -86,6 +84,7 @@
             __init__.py
             settings.py
             urls.py
+            asgi.py
             wsgi.py
 
 These files are:
@@ -113,6 +112,9 @@
   "table of contents" of your Django-powered site. You can read more about
   URLs in :doc:`/topics/http/urls`.
 
+* :file:`mysite/asgi.py`: An entry-point for ASGI-compatible web servers to
+  serve your project. See :doc:`/howto/deployment/asgi/index` for more details.
+
 * :file:`mysite/wsgi.py`: An entry-point for WSGI-compatible web servers to
   serve your project. See :doc:`/howto/deployment/wsgi/index` for more details.


-- ft.markdown:

Finally some real change that should exist. Sometime between 3 and 4 they seem to
have added `asgi.py` and this change must not have been back-ported to django 3.0
docs.


-- ft.code:
lang: diff

@@ -146,16 +148,16 @@
     Ignore the warning about unapplied database migrations for now; we'll deal
     with the database shortly.
 
-You've started the Django development server, a lightweight Web server written
+You've started the Django development server, a lightweight web server written
 purely in Python. We've included this with Django so you can develop things
 rapidly, without having to deal with configuring a production server -- such as
 Apache -- until you're ready for production.
 
 Now's a good time to note: **don't** use this server in anything resembling a
 production environment. It's intended only for use while developing. (We're in
-the business of making Web frameworks, not Web servers.)
+the business of making web frameworks, not web servers.)
 
-Now that the server's running, visit http://127.0.0.1:8000/ with your Web
+Now that the server's running, visit http://127.0.0.1:8000/ with your web
 browser. You'll see a "Congratulations!" page, with a rocket taking off.
 It worked!
 
@@ -204,16 +206,16 @@
 
 .. admonition:: Projects vs. apps
 
-    What's the difference between a project and an app? An app is a Web
-    application that does something -- e.g., a Weblog system, a database of
+    What's the difference between a project and an app? An app is a web
+    application that does something -- e.g., a blog system, a database of
     public records or a small poll app. A project is a collection of
     configuration and apps for a particular website. A project can contain
     multiple apps. An app can be in multiple projects.
 
 Your apps can live anywhere on your :ref:`Python path <tut-searchpath>`. In
-this tutorial, we'll create our poll app right next to your :file:`manage.py`
-file so that it can be imported as its own top-level module, rather than a
-submodule of ``mysite``.
+this tutorial, we'll create our poll app in the same directory as your
+:file:`manage.py` file so that it can be imported as its own top-level module,
+rather than a submodule of ``mysite``.
 
 To create your app, make sure you're in the same directory as :file:`manage.py`
 and type this command:


-- ft.markdown:

Again, all these changes must have gone to 3.0, or even 1.0 for that matter. As you
can see, of all the changes, only the `asgi.py` thing was actually a difference
between django 3 and django 4, and that must have been the only diff we should have
seen. Every other change should have been back ported to the earliest version.

But they can not because of the way they manage versioning.


-- ft.h2: So How Should Version Be Maintained?

Instead of creating a copy of each file by branching (ah yes, sure, git internally
doesn't copy, but that's a git's internal detail, from human operator/user 
perspective it is a copy), we must have a single folder with all versions, one 
folder for each version. But when creating a new version, we must not copy content
of the current version, we must create an **empty** folder and rely on fallback 
logic at documentation build time to fill in the files from the last versions.

For this we create a sparse tree, each version folder only contains a file if that
file is **logically** divergent from the corresponding file in the previous 
version. One can even store just the diff, and maybe that is what we will end up 
doing, but from data structure perspective thinking as if we have only stored the
diff is the right way to think about what I am suggesting.

With this requirement to only copy when there is a logical change, the number of
copies would go down, and humans can easily review if the change is indeed logical.
For that matter, humans may also realise that the change in the software itself 
can be tweaked so this logical change is not needed (I mean if you are changing 
something you are forcing every user of your library to learn something new, and 
if with a small amount of effort you can ensure that no change is needed, no need 
for hundreds and thousands of users to learn something new, isn't that small effort
worth it? And it's not just users you are helping, if you have to maintain one less
diverged file, it will reduce the overall work you have to do in the lifetime of
the project while maintaining the highest quality documentation).


-- ft.h1: SQLite Support!

7th Dec 2021

Yesterday I [started implementing SQLite 
support](https://github.com/FifthTry/fpm/commit/3c2662a6797495c7ead4b7b3bb9c431616b1bf00) 
for FTD documents via `$processor$` mechanism of `ftd`. It was stuck on some 
missing helper utilities in FTD, you can see the two functions at the end with 
`todo!()` as their body. 

Today Arpita is feeling a bit better from the cold, and she has created [PR 
implementing those functions in ftd](https://github.com/FifthTry/ftd/pull/24). She
can't not work even when down it seems!

On that change landed I got the [`$processor$: package-query` 
working](https://github.com/FifthTry/fpm/commit/89d8ba1d1d5f93b5f8b58e306dd8b6b8965f1fb5).
Update the [documentation](/fpm/package-query/) as well.

During implementation, I found out that [`serde-json` support for 
rusqlite](https://docs.rs/rusqlite/0.26.1/rusqlite/types/trait.FromSql.html#impl-FromSql-for-Value) is 
actually, umm, not sure what word to use, not buggy per se, but kind of not as 
useful as I first thought it would be. It converts only the text field to 
`serde_json::Value`, when other fields like integer, float etc can also be easily
converted to `serde_json::Value`. I implemented a [simple converter for other 
sqlite data types as well](https://github.com/FifthTry/fpm/blob/53492bb14f16983569184f0acfd9c1f45ddf1c32/src/library/sqlite.rs#L102-L108).

We are not done yet. We need the ability to pass parameters to queries. Also, those
parameters should be able to refer to other ftd variables. And finally, we should 
be able to read into more types, currently, we only read into records and a list of 
records.


-- ft.h1: Some thoughts on Translation Support

So we have reasonable `sync`/`status`/`diff` working now. We are going to soon 
implement "ad hoc tracking", basically a `.track` folder that contains `foo.track`
like file for each `foo.ftd` file. `status`/`diff` will look into the `.track` file
for any file and see if they are up to date with respect to the files being 
tracked.

Once we have ad-hoc tracking, we are going to work on translation tracking, where
a package would be able to designate itself to be a translation of another package
using `translation-of` key in `FPM.ftd`. When a package tracks another package like
this it means two things.


-- ft.h2: Every File Tracks Corresponding File

All files of the translation package are assumed to be tracking the corresponding 
file for the original package being translated.

In ad-hoc tracking, you have to explicitly add tracking information using planned
`fpm a tracks b` command. But with translation, tracking relationships are 
implicitly assumed.


-- ft.h2: Missing Files and Fallback

It also means that if a file is absent in the translation package, the corresponding
file from the original package is built. 

So to create a translation of another package, you can create an empty package, and
all files of original would be the content of the translation package. And then
you can start translating one file at a time by copying over just that file, so you
do not have to litter your package with files that are just plain copies.


-- ft.h2: Out Of Date File's HTML

So we have translation tracking, which means we know if a file is up to date with
the corresponding file in original package, translation is complete for that file,
but what if it's not up to date? Or even it was never finished? What if you just 
created the translation file, have only translated the heading, what should we show
in those cases?

So far, given a file `a.ftd`, we convert it to `a.html` and that's it. But now for
a file `translated:a.ftd` we have `original:a.ftd`. So we have to consider two 
files when generating `a.html`. In simple case, where `translated:a.ftd` is "up to 
date", we render `translated:a.ftd` and that is that. But if `translated:a.ftd` is
missing or not up to date, we have to include the content of both (and two 
potential diffs, diff of `original:a.ftd` from the date `translated:a.ftd` was last
marked up to date by a human being, to the latest `original:a.ftd`, and diff of 
`translated:a.ftd` when and if it was marked updated date last to latest).

So we have two ftd files and two diffs, and possibly some metadata to include in
the generated `a.html`. We also need some JS to let people switch between 
potentially out of date or incomplete translation and the original version. And we
need an area to show some out of date warnings, and some UI to show/hide the two
diffs.


-- ft.h2: User's Area vs Special Area?

Now that we have more than the content of an `ftd` file to render in any generated
`.html` file, we have to ask ourselves if we should split our UI into two logical 
area, an area completely controlled by end user using ftd, and another for the 
special stuff, like translation out of date messaging?

Tomorrow we will have more stuff, like when we add versioning support, we would
want to show "you are looking at the old version, jump to the latest version" eg 
docs.rs etc, but then if you are seeing a specific version, you want to see two 
diffs as well: diff of what changed in this precise release, so diff from the last 
version to this version, and diff of this version with the latest version. It would
be good if these two bits of info were available at a fingertip without doing 
complex git diff incantations. 

For both versioning and translation, we need to show some sort of "switcher", go to
another language or version of this document.

We can do these by special variables. We can expect each "theme" to know about 
these special variables, and the theme author can include the UI in the most 
logical place. 

We can also create a dedicated "document info" area, say a banner at the top, and 
then theme does not need to bother with all that.

We can even let people customise say `FPM/document-info.ftd` file whose content 
would be included in the special area.

And finally, we can let these writers specify that they have indeed included the
document info in the theme itself and `fpm` should not show 
`FPM/document-info.ftd`, maybe we inherit `FPM/document-info` from the theme and
let the theme set it to an empty file?

There is a little complexity when an FTD document basically says unload me and load
some other document. We do not have an FTD way to do this yet. Not sure if it's a
good idea.

The thing is this is a lot of complexity and a lot of potential changes, at least 
in the early days, leaving it for each theme to individually manage would be a bad
idea as then the confidence with which you can switch theme will go down as you 
will have to verify more things, and not just the look and feel of a theme.


-- ft.h1: Started Design

6th Dec 2021

Jay has created a logo that we kind of like, and some initial design for our 
homepage:


-- ft.image:
src: https://i.imgur.com/axb1vKD.png

This is still under works.


-- ft.h1: SQLite Support

Since we are anyways going to implement some sqlite support for [package 
database](/fpm/~/16/), we may as well let people include arbitrary sqlite files in 
the package, and let people do arbitrary SQL queries on top of any of the sqlite 
databases in the package or any package that is a dependency of this package.

[Change Request](/fpm/~/26/).

[Partially implemented `$processor$: 
package-query`](https://github.com/FifthTry/fpm/commit/3c2662a6797495c7ead4b7b3bb9c431616b1bf00).
Need two methods in `ftd` crate, waiting for Arpita to get better and implement
them.


-- ft.h1: Dynamic Documents and FPM Action

Recently I implemented `$processor$: http`, which paves the way for almost fully
fledged ["dynamic"/data drive documents](///www.fifthtry.com/fpm/~/20/). To really
expose this feature, we can implement arbitrary URL handing, currently only the 
URLs corresponding to actual FTD files is available, this is too limiting as we can
not have author page for example, where we need a URL for each author, and author 
list maybe in a table, or spread all over ftd documents. 

With a `FPM/URLs.ftd`, we can define URL patterns that can contain dynamic data, eg
`/<username>/` etc. We can map each URL pattern to a FTD file, and the file can 
extract the data by defining a schema (eg a record), where the fields of record 
would be populated by URL query parameters, URL fragments (eg `username`) here, or
even request body if its available.

We will sometime need redirect etc, eg if you need login to access something, or
if the page has moved etc. So we need a mechanism to early return, currently its
not possible in a FTD document to let a document say we are done processing the
page. At least we can have some standard variable, eg `fpm.redirect-url`, which 
when set, FPM will ignore the document and return the content of `fpm.redirect-url`
instead, along with some instruction to `fpm.js` to update the URL displayed in
browser.

This is almost the design of [`realm`](///www.amitu.com/realm/). Once I wrote that
I realised we also need an equivalent of "realm actions", and turned out the design
is really easy. Wrote about it in another CR: [fpm 
actions](///www.fifthtry.com/fpm/~/24/). 

The key element of actions is now we need a `fpm.js`, which will have some 
behaviour, and this paves the way for [fpm client 
variables](///www.fifthtry.com/fpm/~/25/).


-- ft.h1: Client Variables

Some variables can only be computed by client. So we need to ship a `fpm.js`, which
will compute them, and pass them to FTD. Some of these variables would also change
during the lifetime of the page.

`fpm.js` will also do some browser history control, for managing server side 
"internal redirect", and `fpm actions`.


-- ft.h1: `fpm sync`, `fpm status` and `fpm diff`

5th Dec 2021

Arpita has been on fire, implemented these three commands. This makes `fpm` puts
some "version control" features in `fpm`. Our goal is not become simplified git,
we definitely take a lot of inspiration from them, but more like advance 
Dropbox/iCloud.

`fpm repo` is needed before we can really call ourselves version control or compare
ourselves with Dropbox/iCloud etc. But if you are using Dropbox/iCloud, you can
already benefit from these commands.

Our goal now is to implement [`adhoc tracking`](/fpm/~/12/), and get to 
[`translation tracking`](/fpm/~/3/).


-- ft.h1: `$processor$: toc` and `$processor$: http`

5th Dec 2021

We implemented [these two processors](/fpm/processors/). TOC processor helps you 
when you are trying to create navigation bars, or table of content of your FPM 
site (this is not the intra page TOC, which we still do not know how to implement).

`$processor$: http` lets you fetch data from any HTTP endpoint that returns JSON 
when rendering a FTD document. It opens up massive opportunities, you can fetch 
data from all sorts of places, data driven graphs and tables etc can be created.


-- ft.h1: Font Support

4th Dec 2021

We just added font support. This allows people to use custom fonts with FTD/FPM.

You can specify the fonts you want loaded in [`FPM.ftd`](/fpm/FPM/) file.


-- ft.h1: Package Dependency Fetching

3rd Dec 2021

Shobhit added support for adding package dependency, and fetching dependencies from
Github or any tar file. We store the dependencies in `.packages`.

Lots still pending, recursive package dependency, or any way to update a package,
looking for packages in FPM_HOME, but its exciting to have this feature land so
soon.


-- ft.h1: Package Database

1st Dec 2021

Wrote about the design of [package database](/fpm/~/16/), basically a sqlite 
database that we will maintain in the initial phase of `fpm build`, and a way to
query that database to get data stored in different ftd documents that are part
of the FPM package.

This can make fpm packages the ideal data sharing format. You can have data 
authored in FTD, and packaged as FPM package, along with some UI code, and publish
them to `fpm repo`. And then other packages can have a dependency on the original 
data package, fpm will download the data, and they can do something more with it, 
create more visualisations, augment data even more using `$processors$` etc, and
maybe publish that package again for other to consume.


-- ft.h1: Update for 30th Nov 2021

Shobhit is working full time on FPM now. We managed to nail down quite a bit of 
our design now.


-- ft.h2: `fpm build` working

Finally we can start using `fpm`. We have created a template repo: 
[FifthTry/fpm-blog](https://github.com/FifthTry/fpm-blog), [rendered 
version](https://fifthtry.github.io/fpm-blog/), which shows how to create a blog 
using FTD and FPM.


-- ft.h2: Design Review With Arpita

Me and Arpita recorded a detailed design review of FPM.


-- ft.youtube:
id: rny1EGkqw_M


-- ft.h1: Kickoff

25th Nov 2021

We have started working on this project now. We have written design docs for quite
a few elements:

- `fpm build`: [file system organization](/fpm/~/1/)
- [logical linking](/fpm/~/2/)
- [translation tracking](/fpm/~/3/)
- [version tracking](/fpm/~/5/)
- [history tracking](/fpm/~/4/)
- [cr tracking](/fpm/~/6/)
- [upstream tracking: two way sync](/fpm/~/7/)
- [`fpm-repo` authentication](/fpm/~/8/)
- [package dependencies](/fpm/~/9/)
- [access control](/fpm/~/10/)

[Shobhit](https://github.com/sharmashobit) is taking the lead of implementing this.
We are hoping to create a minimal version that can convert ftd files to HTML so
`fpm` can be considered an alternative to static site generators.